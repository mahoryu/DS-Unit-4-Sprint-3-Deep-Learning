{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqjOtZ9p9CY3",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_rPueMN9CY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import requests\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI3DjS3l9CZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxvBmpT9CZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.encoding = r.apparent_encoding\n",
        "\n",
        "data = r.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clS1g2iM9CZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c501ef3-1f12-4117-f8f0-6cad1de7b12c"
      },
      "source": [
        "data[:100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\r\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\r\\nShakespeare\\r\\n\\r\\nThis eBo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etiDHH_Y9CZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.split('\\r\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBmt_uCw9CZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skip the Table of Contents\n",
        "data = data[135:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G95vgJ5I9CZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toc = [l.strip() for l in data[44:130:2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE720YPT9CZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "9596bd0e-34c9-4ebf-b9ac-3aa8f58af990"
      },
      "source": [
        "toc"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['For where is she so fair whose uneared womb',\n",
              " 'Or who is he so fond will be the tomb',\n",
              " 'Thou art thy mother’s glass and she in thee',\n",
              " 'So thou through windows of thine age shalt see,',\n",
              " 'But if thou live remembered not to be,',\n",
              " '',\n",
              " '4',\n",
              " 'Unthrifty loveliness why dost thou spend,',\n",
              " 'Nature’s bequest gives nothing but doth lend,',\n",
              " 'Then beauteous niggard why dost thou abuse,',\n",
              " 'Profitless usurer why dost thou use',\n",
              " 'For having traffic with thy self alone,',\n",
              " 'Then how when nature calls thee to be gone,',\n",
              " 'Thy unused beauty must be tombed with thee,',\n",
              " '',\n",
              " '5',\n",
              " 'Those hours that with gentle work did frame',\n",
              " 'Will play the tyrants to the very same,',\n",
              " 'For never-resting time leads summer on',\n",
              " 'Sap checked with frost and lusty leaves quite gone,',\n",
              " 'Then were not summer’s distillation left',\n",
              " 'Beauty’s effect with beauty were bereft,',\n",
              " 'But flowers distilled though they with winter meet,',\n",
              " '',\n",
              " '6',\n",
              " 'Then let not winter’s ragged hand deface,',\n",
              " 'Make sweet some vial; treasure thou some place,',\n",
              " 'That use is not forbidden usury,',\n",
              " 'That’s for thy self to breed another thee,',\n",
              " 'Ten times thy self were happier than thou art,',\n",
              " 'Then what could death do if thou shouldst depart,',\n",
              " 'Be not self-willed for thou art much too fair,',\n",
              " '',\n",
              " '7',\n",
              " 'Lo in the orient when the gracious light',\n",
              " 'Doth homage to his new-appearing sight,',\n",
              " 'And having climbed the steep-up heavenly hill,',\n",
              " 'Yet mortal looks adore his beauty still,',\n",
              " 'But when from highmost pitch with weary car,',\n",
              " 'The eyes (fore duteous) now converted are',\n",
              " 'So thou, thy self out-going in thy noon:',\n",
              " '',\n",
              " '8']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSqbtlJ89CZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9ZIsH_9CZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing Titles\n",
        "locations[9]['title'] = 'THE LIFE OF KING HENRY V'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEv2_Ul_9CZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "6ac16434-d903-4dcf-ebf5-fb595061ee56"
      },
      "source": [
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "# End            \n",
        "for title in toc:\n",
        "    \n",
        "    t = 0\n",
        "    \n",
        "    while t < len(toc):\n",
        "        print(t)\n",
        "        end = locations[t+1]['start'] - 1\n",
        "        locations[t]['end'] = end\n",
        "        t += 1\n",
        "\n",
        "    # Last One\n",
        "    locations[t]['end'] = len(data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b17799167a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlocations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 43"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUDWVElg9CZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c258ed2-a07e-4da6-aab7-5ec758a228fd"
      },
      "source": [
        "locations[9]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end': 63, 'start': 62, 'title': 'THE LIFE OF KING HENRY V'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oCjZe9c9CZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35f07385-83d0-43c2-9abc-6a73f192b109"
      },
      "source": [
        "locations"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'end': 45,\n",
              "  'start': 44,\n",
              "  'title': 'For where is she so fair whose uneared womb'},\n",
              " 1: {'end': 47, 'start': 46, 'title': 'Or who is he so fond will be the tomb'},\n",
              " 2: {'end': 49,\n",
              "  'start': 48,\n",
              "  'title': 'Thou art thy mother’s glass and she in thee'},\n",
              " 3: {'end': 51,\n",
              "  'start': 50,\n",
              "  'title': 'So thou through windows of thine age shalt see,'},\n",
              " 4: {'end': 166766,\n",
              "  'start': 52,\n",
              "  'title': 'But if thou live remembered not to be,'},\n",
              " 5: {'end': 166702, 'start': 166767, 'title': ''},\n",
              " 6: {'end': 57, 'start': 166703, 'title': '4'},\n",
              " 7: {'end': 59,\n",
              "  'start': 58,\n",
              "  'title': 'Unthrifty loveliness why dost thou spend,'},\n",
              " 8: {'end': 61,\n",
              "  'start': 60,\n",
              "  'title': 'Nature’s bequest gives nothing but doth lend,'},\n",
              " 9: {'end': 63, 'start': 62, 'title': 'THE LIFE OF KING HENRY V'},\n",
              " 10: {'end': 65, 'start': 64, 'title': 'Profitless usurer why dost thou use'},\n",
              " 11: {'end': 67,\n",
              "  'start': 66,\n",
              "  'title': 'For having traffic with thy self alone,'},\n",
              " 12: {'end': 69,\n",
              "  'start': 68,\n",
              "  'title': 'Then how when nature calls thee to be gone,'},\n",
              " 13: {'end': 166766,\n",
              "  'start': 70,\n",
              "  'title': 'Thy unused beauty must be tombed with thee,'},\n",
              " 14: {'end': 166736, 'start': 166767, 'title': ''},\n",
              " 15: {'end': 75, 'start': 166737, 'title': '5'},\n",
              " 16: {'end': 77,\n",
              "  'start': 76,\n",
              "  'title': 'Those hours that with gentle work did frame'},\n",
              " 17: {'end': 79,\n",
              "  'start': 78,\n",
              "  'title': 'Will play the tyrants to the very same,'},\n",
              " 18: {'end': 81,\n",
              "  'start': 80,\n",
              "  'title': 'For never-resting time leads summer on'},\n",
              " 19: {'end': 83,\n",
              "  'start': 82,\n",
              "  'title': 'Sap checked with frost and lusty leaves quite gone,'},\n",
              " 20: {'end': 85,\n",
              "  'start': 84,\n",
              "  'title': 'Then were not summer’s distillation left'},\n",
              " 21: {'end': 87,\n",
              "  'start': 86,\n",
              "  'title': 'Beauty’s effect with beauty were bereft,'},\n",
              " 22: {'end': 166766,\n",
              "  'start': 88,\n",
              "  'title': 'But flowers distilled though they with winter meet,'},\n",
              " 23: {'end': 166694, 'start': 166767, 'title': ''},\n",
              " 24: {'end': 93, 'start': 166695, 'title': '6'},\n",
              " 25: {'end': 95,\n",
              "  'start': 94,\n",
              "  'title': 'Then let not winter’s ragged hand deface,'},\n",
              " 26: {'end': 97,\n",
              "  'start': 96,\n",
              "  'title': 'Make sweet some vial; treasure thou some place,'},\n",
              " 27: {'end': 99, 'start': 98, 'title': 'That use is not forbidden usury,'},\n",
              " 28: {'end': 101,\n",
              "  'start': 100,\n",
              "  'title': 'That’s for thy self to breed another thee,'},\n",
              " 29: {'end': 103,\n",
              "  'start': 102,\n",
              "  'title': 'Ten times thy self were happier than thou art,'},\n",
              " 30: {'end': 105,\n",
              "  'start': 104,\n",
              "  'title': 'Then what could death do if thou shouldst depart,'},\n",
              " 31: {'end': 166766,\n",
              "  'start': 106,\n",
              "  'title': 'Be not self-willed for thou art much too fair,'},\n",
              " 32: {'end': 166694, 'start': 166767, 'title': ''},\n",
              " 33: {'end': 111, 'start': 166695, 'title': '7'},\n",
              " 34: {'end': 113,\n",
              "  'start': 112,\n",
              "  'title': 'Lo in the orient when the gracious light'},\n",
              " 35: {'end': 115,\n",
              "  'start': 114,\n",
              "  'title': 'Doth homage to his new-appearing sight,'},\n",
              " 36: {'end': 117,\n",
              "  'start': 116,\n",
              "  'title': 'And having climbed the steep-up heavenly hill,'},\n",
              " 37: {'end': 119,\n",
              "  'start': 118,\n",
              "  'title': 'Yet mortal looks adore his beauty still,'},\n",
              " 38: {'end': 121,\n",
              "  'start': 120,\n",
              "  'title': 'But when from highmost pitch with weary car,'},\n",
              " 39: {'end': 123,\n",
              "  'start': 122,\n",
              "  'title': 'The eyes (fore duteous) now converted are'},\n",
              " 40: {'end': 166766,\n",
              "  'start': 124,\n",
              "  'title': 'So thou, thy self out-going in thy noon:'},\n",
              " 41: {'end': 166694, 'start': 166767, 'title': ''},\n",
              " 42: {'start': 166695, 'title': '8'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP5LMpzc9CZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e928af2-faba-4095-8d25-a773cc0c00ab"
      },
      "source": [
        "for e, i in enumerate(data):\n",
        "    \n",
        "    if \"ALL’S WELL THAT ENDS WELL\" in i:\n",
        "        print(e)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zni9Y73h9CZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35e08571-5727-469e-85dc-884170c04a2f"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE SONNETS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNw8Hjsv9CZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divide b/w plays and sonets\n",
        "sonets = data[:2776]\n",
        "plays = data[2777:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDyJVse9CZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8929ac2d-fe9d-4af4-d886-4a9825511abd"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'THE SONNETS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_DAhn7t9CZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def long_lines(lst_ln):\n",
        "    clean = []\n",
        "    \n",
        "    for ln in lst_ln: \n",
        "        \n",
        "        if len(ln) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            pct = len(ln.strip(' ')) / len(ln)\n",
        "\n",
        "            if pct >= .5:\n",
        "                clean.append(ln.lstrip())\n",
        "\n",
        "    return clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQmdsCzI9CZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# May Not be Needed\n",
        "#sonets = long_lines(sonets)\n",
        "#plays = long_lines(plays)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBAQm73U9CZ6",
        "colab_type": "text"
      },
      "source": [
        "## Word Encoding\n",
        "\n",
        "This is just a start, and is not complete yet. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FO6jakK9CZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(set(\"\\r\\n\".join(plays).split()))\n",
        "words = [line.split() for line in plays]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltLhQIGG9CZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c7727a5-0c26-437e-ff61-282c6aa81024"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld83v67z9CaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1f95241a-2e4b-456a-fa94-db3bdf20e26c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "vocab_df = pd.DataFrame(vocab, columns=[\"vocab\"])\n",
        "vocab_df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aerial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>detects</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mint.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>weal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abetting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      vocab\n",
              "0    aerial\n",
              "1   detects\n",
              "2     mint.\n",
              "3      weal\n",
              "4  Abetting"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8dC_yqs_ehg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45cc5f93-3f9d-46fc-9301-be70f28a7dce"
      },
      "source": [
        "text = \" \".join(vocab_df.vocab.values)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} \n",
        "\n",
        "print(len(chars))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59xZbBbS_qye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0c4c80f8-2d9b-43b2-9980-acf3ed4dd789"
      },
      "source": [
        "print(chars)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[']', 'o', 'é', '4', 'Y', 'U', '.', 'F', 'h', \"'\", 'ê', 'Æ', 'à', 'u', 'v', 'f', 'L', 'ç', '|', 'V', 'a', '}', 'æ', '/', 'd', 'e', 'j', ' ', 'B', '7', ';', 'Z', 'H', 'D', 'M', 'b', 'l', 'z', 'P', 'O', '[', 'p', '*', '%', 'J', 'A', 'X', 'c', '”', 'E', '-', '(', 'r', '$', 'î', 'n', 'Q', ',', 'q', 'K', 's', '‘', '\\\\', 'R', 'i', '6', 'â', '’', 'm', '`', ':', 'W', '@', 'œ', 't', 'I', 'N', 'S', '1', '2', '_', '0', 'y', 'k', 'x', '?', '!', '&', 'G', 'É', '9', 'C', '3', 'è', 'w', '“', '—', ')', 'T', '\"', '8', '5', 'g']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfD9D5qp_v_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_df['vocab_clean'] = vocab_df['vocab'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FXz1875_6RH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97a17d91-90a9-4746-f521-f34047bd0e21"
      },
      "source": [
        "text = \" \".join(vocab_df.vocab.values)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} \n",
        "\n",
        "print(len(chars))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiDu7AYDADuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c99bb745-49f6-48ea-ae6e-3b4bef181e28"
      },
      "source": [
        "print(chars)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[']', 'o', '4', 'Y', 'U', '.', 'F', 'h', \"'\", 'u', 'v', 'f', 'L', '|', 'V', 'a', '}', '/', 'd', 'e', 'j', ' ', 'B', '7', ';', 'Z', 'H', 'D', 'M', 'b', 'l', 'z', 'P', 'O', '[', 'p', '*', '%', 'J', 'A', 'X', 'c', 'E', '-', '(', 'r', '$', 'n', 'Q', ',', 'q', 'K', 's', '\\\\', 'R', 'i', '6', 'm', '`', ':', 'W', '@', 't', 'I', 'N', 'S', '1', '2', '_', '0', 'y', 'k', 'x', '?', '!', '&', 'G', '9', 'C', '3', 'w', ')', 'T', '\"', '8', '5', 'g']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k8I-r3z_8VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_df['vocab_clean'] = vocab_df['vocab'].replace({r'[^a-zA-Z0-9_!?\\-\\'\".,]': ''}, regex=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D8CuB5uAPUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fed2a41-b1ec-4841-b7b2-d519983dc502"
      },
      "source": [
        "text = \" \".join(vocab_df.vocab.values)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} \n",
        "\n",
        "print(len(chars))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn0NyQXtBQS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0d7b7e5f-de18-406f-d7fe-efbe80bd2ae2"
      },
      "source": [
        "print(chars)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['t', 'I', 'N', 'o', 'E', '-', 'r', 'S', '4', 'd', 'n', '1', 'Y', 'Q', 'U', '.', ',', 'e', 'W', 'j', 'q', 'K', '2', 's', ' ', '_', '0', 'B', 'F', '7', 'h', 'y', 'Z', 'k', 'H', 'D', 'M', 'b', 'x', '?', 'l', 'R', 'X', 'z', \"'\", 'O', '!', 'P', 'G', '9', 'C', 'i', 'p', 'u', '3', 'v', 'f', '6', 'L', 'w', 'J', 'V', 'T', 'm', 'a', '\"', '8', 'A', 'c', '5', 'g']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrVdU2Rz9CaD",
        "colab_type": "text"
      },
      "source": [
        "## Character Encoding\n",
        "\n",
        "Using the technique shown in lecture. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QdwTc5j9CaE",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d79247b-139d-4a61-912f-90113532443c"
      },
      "source": [
        "text = '\\r\\n'.join(sonets)\n",
        "\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c:i for i,c in enumerate(chars)}\n",
        "int_char = {i:c for i,c in enumerate(chars)}\n",
        "\n",
        "print(f\"Our corpus contains {len(chars)} unique characters.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our corpus contains 73 unique characters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie-lBBku9CaG",
        "colab_type": "code",
        "colab": {},
        "outputId": "b878f042-8d61-4c58-ed6a-6430d79e6cfa"
      },
      "source": [
        "# Create the Sequence Data\n",
        "\n",
        "maxlen = 150\n",
        "step = 1\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 characters long\n",
        "next_chars = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_chars.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences:', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences: 100978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4NCSb69CaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Specify x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_chars[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLZqhQWA9CaM",
        "colab_type": "code",
        "colab": {},
        "outputId": "2e5a9791-4b97-443c-c154-e0ba41fec117"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100978, 150, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wmaIRDt9CaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ymyuw9V9CaS",
        "colab_type": "code",
        "colab": {},
        "outputId": "4fde1647-1ffa-4bba-97a3-54e266d599a4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1028)              4531424   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 73)                75117     \n",
            "=================================================================\n",
            "Total params: 4,606,541\n",
            "Trainable params: 4,606,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtTgpNKy9CaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiqDySjo9CaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KveVTRJc9CaY",
        "colab_type": "code",
        "colab": {},
        "outputId": "bb4cfe53-b74c-4d25-af75-1bb11f7ad221"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          validation_split=.2,\n",
        "          epochs=100,\n",
        "          callbacks=[print_callback, \n",
        "                     #EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\n",
        "                     tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80782 samples, validate on 20196 samples\n",
            "Epoch 1/100\n",
            " 2048/80782 [..............................] - ETA: 26:02 - loss: 4.0877\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"Each changing place with that which goes before,\n",
            "In sequent toil all forwards do contend.\n",
            "Nativity once in the main of light,\n",
            "Crawls to maturity, w\"\n",
            "Each changing place with that which goes before,\n",
            "In sequent toil all forwards do contend.\n",
            "Nativity once in the main of light,\n",
            "Crawls to maturity, wcyoObdsGhahotnlrior soGdon\n",
            "diirhma\n",
            "s2flhEA srSosiiGnohr\n",
            " cuish\n",
            "swhothuhgn\n",
            "s8i5hplhsahbhv\n",
            "!hr Phodhho ihrlhnzolhivuoiRr rhf3h\n",
            "izws\n",
            "olhaaonhyloAwisellollhhh,lnOt5htrzhylsTnh criYvl1ehyTsaagrwsFchDbriBo:isnhlnotAtOr.rooslatthh,o,S dsf 5ol ohbrlt?(rtronEhnilr5ghc,svrimash,b, ogBaalOxSgochhwthoif!Rn do5wqcgnn at3krwn.\n",
            "sdssiil,olamrr Tlohg,r\n",
            "yrOhwioe\n",
            "wiwJtlfia3soofvadAytaytc p,mhiGo oyvf rtn5h\n",
            " 2048/80782 [..............................] - ETA: 1:09:39 - loss: 4.0877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3fec21fe2220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           callbacks=[print_callback, \n\u001b[1;32m      9\u001b[0m                      \u001b[0;31m#EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                      tensorboard_callback])\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrzK62-39Caa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EqXd0cx9Cab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}